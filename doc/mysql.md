# MySQL

[mysql执行顺序](https://www.cnblogs.com/wyq178/p/11576065.html)

## MySQL基础架构

![mysql执行过程](https://image-1301573777.cos.ap-chengdu.myqcloud.com/mysql执行过程.png)

### 连接器

连接器的主要职责就是:

①负责与客户端的通信,是半双工模式,这就意味着某一固定时刻只能由客户端向服务器请求或者服务器向客户端发送数据,而不能同时进行,其中mysql在与客户端连接TC/IP的

②验证请求用户的账户和密码是否正确,如果账户和密码错误,会报错:Access denied for user 'root'@'localhost' (using password: YES)

③如果用户的账户和密码验证通过,会在mysql自带的权限表中查询当前用户的权限:

mysql中存在4个控制权限的表，`分别为**user表，db表，tables_priv表，columns_priv表**,`mysql权限表的验证过程为：

1:`User表:`存放用户账户信息以及全局级别（所有数据库）权限，决定了来自哪些主机的哪些用户可以访问数据库实例
 **Db表:**存放`数据库级别`的权限，决定了来自哪些主机的哪些用户可以访问此数据库 
 **Tables_priv**表：`存放表级别的权限`，决定了来自哪些主机的哪些用户可以访问数据库的这个表 
 **Columns_priv**表：`存放列级别的权限`，决定了来自哪些主机的哪些用户可以访问数据库表的这个字段 
 **Procs_priv**表：`存放存储过程和函数`级别的权限

2:先从user表中的Host,User,Password这3个字段中判断连接的ip、用户名、密码是否存在，存在则通过验证。

3:通过身份认证后，进行权限分配，按照user，db，tables_priv，columns_priv的顺序进行验证。即先检查全局权限表user，如果user中对应的权限为Y，则此用户对所有数据库的权限都为Y，将不再检查db, tables_priv,columns_priv；如果为N，则到db表中检查此用户对应的具体数据库，并得到db中为Y的权限；如果db中为N，则检查tables_priv中此数据库对应的具体表，取得表中的权限Y，以此类推

4:如果在任何一个过程中权限验证不通过,都会报错

### 缓存

> ​	mysql的缓存主要的作用是为了提升查询的效率，缓存以key和value的哈希表形式存储，key是具体的sql语句，value是结果的集合。如果无法命中缓存,就继续走到分析器的的一步,如果命中缓存就直接返回给客户端 。不过需要注意的是在mysql的8.0版本以后，缓存被官方删除掉了。之所以删除掉,是因为查询缓存的失效非常频繁,如果在一个写多读少的环境中,缓存会频繁的新增和失效。对于某些更新压力大的数据库来说，查询缓存的命中率会非常低

**关闭缓存**

```sql
query_cache_type=DEMAND
```

**使用缓存**

```sql
mysql> select SQL_CACHE * from T where ID=10；
```

### 分析器

> 如果没有命中缓存，就要开始真正执行语句了。它会将输入的Sql做语法分析，判断你输入的SQL语句是否满足MySQL的语法。如下面语句，会报出“You have an error in your SQL syntax”的错误提醒
>
> ```sql
> mysql> elect * from t where ID=1;
> ```

### 优化器

> 优化器的作用就是决定选择使用哪一个方案。示例一中两种查询方案都符合要求，但是效率会不同，MySQL会根据优化器来筛选出最有方案。

**示例**

```sql
 mysql> select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;
```

- 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。
-  也可以先从表 t2 里面取出 c=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。

### 执行器

**校验权限**

```sql
mysql> select * from T where ID=10;
ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'
```

**调用接口**

比如我们这个例子中的表 T 中，那么执行器的执行流程是这样的：

- 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果中； 
- 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
- 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 

至此，这个语句就执行完成了。

### MySQL执行顺序

![SQL执行顺序](https://image-1301573777.cos.ap-chengdu.myqcloud.com/SQL执行顺序.png)

## InnoDB总体架构

### 内存结构

#### Buffer Pool-缓冲池

​	缓冲池的作用就是解决频繁的磁盘IO导致效率低下的问题,它**缓存的是页面信息，包括数据也、索引页**。

​	预读:MySQL在读取数据时，**并不是按需读取，而是按页读取（磁盘访问按页读取能够提高性能），同时按页读取一般是读取附近的数据，**一次至少读一页数据（操作系统是4K，InnoDB默认为16K），如果未来要读取的数据就在页中，就能够省区后续的磁盘IO，提高效率。那么缓冲页是采用什么算法来进行更新呢？(新老带-LRU算法：https://www.pianshen.com/article/44151236867/)

#### Change Buffer写缓冲

### 磁盘结构

> 表空间可以看作是InnoDB存储引擎逻辑结构的最高层，所有数据都存放在表空间。



### 











## MySQL事务

### 事务的特性

- 原子性
- 一致性
- 隔离性
- 持久性

### 事务隔离级别

在多个事务同时执行下，就可能出现脏读（脏读）（dirty read）、不可重复读（non reapeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级 别”的概念。

- 读未提交（`read uncommitted`）

  > 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。**会出现如下图所示的脏读**

  ![image-20210323222243025](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210323222243025.png)

- 读提交（`read committed`）

  > 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。**会出现不可重复读的问题，如下图**

  ![image-20210323222508773](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210323222508773.png)

- 可重复读（`repeatable read`）

  > 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一 致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。**会出现幻读问题，如下图**

  ![image-20210323224417459](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210323224417459.png)

- 串行化（`serializable`）

  > 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现 读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

下面示例来了解这四个隔离级别：

![image-20210319082838757](C:\Users\fuzy\AppData\Roaming\Typora\typora-user-images\image-20210319082838757.png)

我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、 V3 的返回值分别是什么。

- 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果 已经被 A 看到了。因此，V2、V3 也都是 2。

- 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看 到。所以， V3 的值也是 2。 

- 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这 个要求：事务在执行期间看到的数据前后必须是一致的。 

  > 使用场景：假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时 候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。 你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。

- 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。

​     在实现上，数据库里面会创建一个**视图**，访问的时候以视图的逻辑结果为准。**在“可重复读”隔 离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔 离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提 交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁 的方式来避免并行访问。**

### InnoDB对隔离级别的支持

![image-20210323224817701](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210323224817701.png)

**如果事务隔离级别设置串行化，那么效率会大大降低，所以InnoDB引擎引用了其他方案来解决一个事务中前后两次读取数据结果不一致的问题。**

### MVCC

> ​	如果要让一个事务前后两次读取的数据保持一致，那么我们可以在修改数据之前给他建立一个**备份（快照）**，在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。**注意，这个快照是基于整库的。**后面再来读取这个快照就行了，这种方案叫做多版本的并发控制`Multi Version Concurrency Controll(MVCC)`。

**快照是怎么实现的？**

​	**InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的**。

​	**而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且 把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保 留，并且在新的数据版本中，能够有信息可以直接拿到它。**

如下图所示，就是一个记录被多个事务连续更新后的状态：

![image-20210329220005279](C:\Users\fuzy\AppData\Roaming\Typora\typora-user-images\image-20210329220005279.png)

​																						**行状态变更图**

图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。

sql语句在更新时会生成undo log日志，**那么undo log是怎么回滚日志的呢**？

> ​	如上图行状态变更图，图中的三个虚线箭头，就是undo log；而V1，V2，V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undo log计算出来的。比如，需要 V2 的时候，就是 通过 V4 执行 U3、U2 算出来。

**可重复读的实现**

​	**按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。**

​	因此，InnoDB 代码实现上，一个事务只需要在启动的时候，找到所有已经提交的事务 ID 的最 大值，记为 up_limit_id；然后声明说，**“如果一个数据版本的 row trx_id 大于 up_limit_id，我就不认，我必须要找到它的上一个版本”。当然，如果一个事务自己更新的数据，它自己还是 要认的。”**

**现在我们来看下面这个例子：**

![image-20210329213448057](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210329213448057.png)

**假设K的初始值是1，事务的隔离级别是RR(可重复读)，猜想返回的结果是什么？**

> **我们可以惊讶的发现事务B中Q1得到的结果是3，Q2中的到的结果是1。**

我们利用上面的MVCC特性（**所有数据都有多个版本**）来分析这个结果：

- 假设事务A开始前事务最大ID是99；
- 假设事务A、B、C的版本好分别是100、101、102，且当前系统没有其他事务
-  假设三个事务开始前，id=1的这一行数据的 row trx_id 是 90。

按照上面的假设最后我们的到下面这张图

![image-20210329221924807](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210329221924807.png)

> ​	从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的 最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。
>
> ​	 第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。 
>
> ​	好，现在事务 A 要来读数据了，它的 up_limit_id 是 99。当然了，读数据都是从当前版本读起 的。所以，Q2 的读数据流程是这样的：
>
> - 找到 (1,3) 的时候，判断出 row trx_id=101 大于 up_limit_id，要不起；
> -  接着，找到上一个历史版本，一看 row trx_id=102，还是要不起； 
> - 再往前找，终于找到了（1,1)，它的 row trx_id=90，是可以承认的数据。 **这样执行下来，事务 A 读到的这个数据，跟它在刚开始启动的时候读到的相同，所以我们称之 为一致性读。**

那么又引出一个问题，事务B的update操作是读取哪个版本的数据？

​	自然是在事务C更新后获取到的数据，因为如果不是按照这样规则，那么事务C更新的操作就会丢失，明明进行了两次update操作，最后丢失了事务C的操作，导致数据丢失。所以引用到了这样一条规则：**更新数据都是先读后写的，而这个读，只能读当前的值，称 为“当前读（current read）”。**

​	所以，在执行事务 B 的 Q1 语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，可以用，所以 Q1 得到的 k 的值是 3。

综上：**可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。 如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。**

**读提交实现**

- 在可重复读隔离级别下，只需要在事务开始的时候找到那个 up_limit_id，之后事务里的其他 查询都共用这个 up_limit_id；
-  在读提交隔离级别下，每一个语句执行前都会重新算一次 up_limit_id 的值。

所以针对上例中，如果使用隔离级别是**读提交的**，那么他每次都会重新计算一次up_limit_id，由于Q2提交后事务后trx_id就变成了102>101，所以返回了K=3。

MVCC的原则：

- 一个事务看到的数据版本
  - 第一次查询之前已经提交的事务的修改
  - 本事务的修改

- 一个事务不能看见的数据版本
  - 在本事务第一次查询之后创建的事务
  - 活跃的（未提交的）事务的修改

**MVCC的效果：可以查到这个事务开始之前已经存在的数据，即使它在后面被删除或者修改了。而在我这个事务之后新增的数据，我是查不到的。**

### Read View-事务隔离级别的实现





### Mysql锁

#### 全局锁

> **对整个数据库实例加锁，让整个数据库处于只读状态**。MySQL 提供了一个加全局读锁的方法，命令是**`Flush tables with read lock `**。当客户端断开时，就会自动释放锁。

**全局锁的典型使用场景是，做全库逻辑备份**。

只让整个库只读，听上去很危险：

- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆； 
- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。

但是试想一下，假设你没有使用全局锁进行数据库备份，假设此时一个用户发起了一个下单操作（需要锁库存和生成订单），假设时间顺序上先锁库存后生成订单，那么可能在备份期间的时候库存已被锁定，但是订单还没有生成，如果后期利用备份数据回复数据就会导致库存扣了但是订单没生成，那么此时备份的数据和实际数据不一致，如下：

| 数据库 操作 | 备份               |
| ----------- | ------------------ |
| 锁库存      |                    |
|             | 开始备份（库存表） |
|             | 开始备份订单表     |
| 生成订单    |                    |

**当然这是在没有事务的情况下备份可能会出现的结果，但是一些业务场景中即使业务失败也要保存对应日志记录，此时备份文件就会丢失日志记录。**

数据库中进行全局锁模拟语句：

```sql
Flush tables with read lock;
begin;
	UPDATE `demo`.`user` SET `age` = 1, `name` = 'demo' WHERE `id` = 1;
commit;

--错误信息
UPDATE `demo`.`user` SET `age` = 1, `name` = '傅某' WHERE `id` = 1
> 1223 - Can't execute the query because you have a conflicting read lock
> 时间: 0s
```

#### 表级的锁

##### 表锁

> **对表实例加锁，让整个表处于只读状态**。命令是**`是 lock tables … read/write `**。可以用 unlock tables 主动释放 锁，也可以在客户端断开的时候自动释放。

**需要注意，lock tables 语法除了会限制别的线程的 读写外，也限定了本线程接下来的操作对象。**

举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。**同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、 写 t2 的操作。连读 t2 都不允许，自然也不能访问其他表。**

**示例1-单线程锁表只读 read**

```sql
----查询操作 正常
begin;
	lock tables `user` read;
	select * from `user`;
commit;

----更新操作 提示：Table 'user' was locked with a READ lock and can't be updated
begin;
	lock tables `user` read;
	UPDATE `demo`.`user` SET `age` = 1, `name` = 'fuzy' WHERE `id` = 1;
commit;
```

****

**示例2-单线程锁表可写 write**

```sql
----查询操作一直处于等待中
begin;
	lock tables `user` WRITE;
	select * from `user`;
commit;

----更新操作成功d
begin;
	lock tables `user` WRITE;
	UPDATE `demo`.`user` SET `age` = 1, `name` = 'fuzy' WHERE `id` = 1;
commit;
```

##### 元数据锁（MDL）

> MDL 不需要显式使用，**在访问一个表的时候会被 自动加上**。MDL 的作用是，保证读写的正确性。

在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读 锁；当要对表做结构变更操作的时候，加 MDL 写锁。 

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 
- 读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线 程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

MDL锁可能会出现的问题：**长事务，事务不提交，就会一直占着 MDL 锁**。最后会导致读写都不可用。如下图：

![image-20210328122153851](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210328122153851.png)

> 我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。
>
> 由于 session B 需要的也 是 MDL 读锁，因此可以正常执行。
>
>  之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。
>
>  如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请 求也会被 session C 阻塞。
>
> 前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁， 就都被锁住，等于这个表现在完全不可读写了。

​	所以基于以上分析，我们要解决长事务的问题；**实际业务中，如果遇到长事务的问题，同时需要修改字段或者增加字段，那么我们考虑使用kill命令杀死这个长事务。**

​	**但如果我们要变更的是一个热点表，数据量不大，但是请求很频繁，而你必须要添加这个字段该怎么办？**

​	**这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句 里面设定等待时间(sql语法如下)，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻 塞后面的业务语句，先放弃。**

```sql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ... 
```

#### 行锁

> ​	顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时 候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。
>
> ​	MySQL 的行锁是在引擎层由各个引擎自己实现的。InnoDB 是支持行锁 的。相比较其全局锁和表锁，行锁细粒度更低。
>
> ​	在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释 放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**所以在设计功能时，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。这样提升了并发度**

#### 死锁

> 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致 这几个线程都进入无限等待的状态，称为死锁。如下图，是造成死锁的可能原因：

![image-20210329073124779](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210329073124779.png)

解决死锁的策略：

- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
-  另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事 务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

实际业务中怎么解决由热点行更新导致的性能问题呢？

​	如果使用第一种策略，耗时严重；使用第二种策略，每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁 住，如此循环，最后判断是否出现了循环等待，也就是死锁。这种情形时间复杂度极高，严重消耗CPU资源。

​	**最常见的解决办法就是采用第二种策略，然后在设计上考虑通过将一行改成逻辑上的多行来减少冲突。**

#### 共享锁（读写锁）

行级别的人锁，阻塞其他事务修改

#### 排他锁（独占锁）

行级别的锁

#### 意向锁

表级别的锁

#### 行锁的原理

- 在没有索引的情况下，`for update`一行数据整个表会被锁住

  ​	一张表没有主键索引，InnoDB引擎会选择第一个不包含NIULL值的唯一索引作为主键索引，如果也没有这样的索引，InnoDB会选择内置6字节长的ROWID作为隐藏的聚集索引，它会随着行记录的写入而递增。

  ​	所以为什么会锁表，是因为查询没有用索引，或进行全表扫描，然后把每一个隐藏的聚集索引都锁住了。

- 在只有主键索引的情况下，`for update`获取同一行数据失败

- 在既有主键又有普通索引的情况下，用普通索引作为查询条件(where) 进行`for update`，当用主键查询该行数据是依然会失败

  ​	在InnoDB中，二级索引最终是通过主键索引来查询数据的，本质上是因为锁定的是同一行数据，是相互冲突的。

#### 行锁的算法

##### 记录锁

​	我们针对唯一性的索引（包括唯一索引和主键索引）使用等值查询（`select * from user where id=1 for update`）精准匹配到一条记录时，这个时候就用记录锁。

##### 间隙锁

​	我们使用等值（id=1）或范围查询（id>1 and id<10），没有命中任何一条记录时，它使用的都是间隙锁。间隙锁主要是阻塞insert操作，相同的间隙锁之间不冲突。

##### 临键锁



### 事务隔离的实现

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![image-20210319084222289](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210319084222289.png)

对于 read-view A，要得到 1，就必须 将当前值依次执行图中所有的回滚操作得到。同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对 应的事务是不会冲突的。

### 事务的启动方式

MySQL 的事务启动方式有以下几种：

- 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句 是 rollback。 
- set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。

​     有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下 来的查询都在事务中，如果是长连接，就导致了意外的长事务。长事务意味着系统里面会存在很老的事务视图，会占用大量的存储空间。

你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用 于查找持续时间超过 60s 的事务。

```sql
1 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

## MySQL日志

### 更新SQL过程

​	当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做（记录bin log）。

### redo log

- 循环写入，当空间满了，就将数据更新到磁盘，然后清理前面的空间，继续追加写入

- 数据写入内存

- InnoDB引擎特有的日志,redo log位于`/var/lib/mysql`目录下的`ib_logfile()`和`ib_logfile1`，默认2个文件，每个48m。
- redo log大小是固定的，前面的内容被股改，一旦被写满，就会触发将日志同步到磁盘的操作，以便腾出空间记录后面的修改

### Undo log

​	撤销日志或回滚日志。如果修改数据时出现异常，可以用`undo log`来实现回滚操作。

### bin log

​	将数据写入磁盘，持久化。

### 更新SQL的过程

sql语句`update teacher set name='彭于晏' where id='1'`

![image-20210321115531770](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210321115531770.png)

- 先查询数据，如果有缓存，也会使用到缓存
- 修改`id=1`的用户姓名，然后调用引擎接口，写入这一行数据到内存中，融通是记录redo log，此时redo log进行准备状态，然后告诉执行器执行完成了随时可以提交。
- 执行器收到通知开始记录binlog，然后调用存储引擎接口，设置redo log为commit状态
- 更新完成

### 两阶段提交

上述更新SQL过程中，分别是在Server层与InnoDB引擎层进行提交事务的，所以这就涉及到两阶段提交概念。具体概念可以参考这篇文章：https://zhuanlan.zhihu.com/p/111304281

如果没有两阶段提交会发生什么?

- 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行的值。 但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之 后备份日志的时候，存起来的 binlog 里面就没有这条语句。 然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢 失，这个临时库就会少了这一次更新与原库的值不同。 
- 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃 恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把name修改成彭于晏”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来 的这一行与原库的值不同。

### bin log与redo log的区别

1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可 以使用。 
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志， 记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
4. redo log是写入内存的，bin log是写入磁盘的。

## 索引模型

### 索引模型的推演

#### 二分查找树

> 二分查找树（左节点都小于父节点，右子树都大于父节点）能够实现快速查找，又能实现快速插入，但是存在一个问题：它的查找耗时是和这棵树的深度相关的，在最坏的情况下时间复杂度会退化成O(n)（**当父节点是最大或者最小时**）。如下图：

![image-20210321212109497](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210321212109497.png)

#### 平衡二叉树（AVL Trees）

> 左右子树的深度差绝对值不能超过1。它是通过旋转来保证树的平衡。
>
> 如下图AVL树存储了索引的值，还要存储完整记录在磁盘上的地址。同时需要存储左右子树的指针。

![image-20210321212854072](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210321212854072.png)

**如上图，每个磁盘块代表一个页数据，大小是16K；那么一个树的节点需要设计成16K的大小，不然就会出现读不完或者读不够的情况。另外存在严重的性能问题，就是每次从磁盘读取都发生一次IO操作，树的深度越大，消耗性能就越大。所以设计者就进行优化，减少树的深度，增加分叉。**

#### 多路平衡查找树（Balanced Tree）

> 为了解决平衡二叉树带来的磁盘IO过多导致查询效率过低的问题，就引入了`B Tree`，如下图：

![image-20210321213810616](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210321213810616.png)

**该结构特点：分叉树永远比关键字数多1，比如上图画的树，每个节点存储两个关键字，那么就会有三个指针指向三个子节点（当然肯定不只存3个这么少）。**

#### B+树

![image-20210322073513359](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210322073513359.png)

特点：

- 关键字的数量是跟路数相等的
- B+Tree的根节点和枝节点中都不会存储数据，只有叶子节点才存储数据。
- B+Tree的每个叶子节点增加了一个指向相邻叶子节点的指针，它的最后一个数据会指向下一个叶子节点的第一个数据，形成了一个有序链表的结构。

#### 红黑树

为什么没有使用红黑树？（层数过多，导致IO过多）

红黑树的特点：

- 节点分为红色或黑色
- 根节点必须是黑色的
- 叶子节点都是黑色的NULL节点
- 红色节点的两个子节点都是黑色（不允许两个相邻的红色节点）
- 从任意节点出发，到其每个叶子节点的路径中包含相同数量的黑色节点

### MyISAM引擎索引结构

在以MyISAM引擎存储的mysql结构中，我们可以找到(.frm、.MYD、.MYI)三个后缀名结尾的文件；

- **.frm后缀结尾的文件对于任何存储引擎都会生成该文件。**
- **.MYD后缀结尾的文件，存放的是数据记录**
- **.MYI结尾的文件存放的是索引文件（一个索引就会有一颗B+Tree，所有的B+Tree都在这个文件里面）**

**那么如何根据对应的索引找到数据呢?**

​	在MyISAM的结构里面，叶子节点存储的是数据文件对应的磁盘地址。所以从索引文件.MYI中找到键值后，会到数据文件.MYD中获取相应的数据记录，如下图：

![image-20210322213731071](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210322213731071.png)

针对主键索引和普通索引，MyISAM存储引擎都会一样对待，从.MYI里面找到键值，然后查找数据。

![image-20210322213859725](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210322213859725.png)

### InnoDB引擎索引结构

​	在InnoDB引擎中，一张表可能会有多个索引，数据肯定只有一份，那么数据是存储在哪个索引的叶子节点上呢？

![image-20210322225424008](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210322225424008.png)

由上图引入一个概念：**聚簇索引（索引键值的逻辑顺序跟表数据行的物理存储顺序一致）**。

![image-20210322224947766](https://image-1301573777.cos.ap-chengdu.myqcloud.com/image-20210322224947766.png)

如上图：

​	InnoDB中，主键索引存储索引和数据，**索引键值的逻辑顺序与表数据行的物理存储顺序一致，也就是聚簇索引。**其他的索引统一称为**二级索引**。

​	如果直接使用主键索引查询数据，可以在索引文件中直接找到数据行；如果通过二级索引查询数据，需要先找到二级索引，然后在根据主键索引查询对应的数据。

但是如果一张表没有主键索引怎么办？那完整的记录放在哪个索引的叶子节点？或者这张表根本没有索引？数据放在那里？

- 如果我们定义了主键，那么InnoDB会选择主键作为聚簇索引。
- 如果没有显式定义主键，则InnoDB会选择第一个不包含NULL值的唯一索引作为主键索引。
- 如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐藏的聚集索引，它会随着行记录的写入而主键递增